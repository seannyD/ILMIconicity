hist(datax[datax$condition=='Comm',]$increaseIconicity)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
dens.comm = density(datax[datax$condition=='Comm',]$increaseIconicity)
dens.learn = density(datax[datax$condition=='Learn',]$increaseIconicity)
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
getIconicity <- function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
}
####
cleanWords = function(x){
gsub("รง",'c',x)
}
processGeneration = function(folder){
bits = strsplit(folder,"_")[[1]]
chain = bits[4]
gen = bits[5]
condition =   "Comm"
if(!"Comm" %in% bits){
condition = "Learn"
}
resFile = list.files(folder, pattern='*.OUT')
d = read.delim(paste(folder,"/", resFile,sep=''),sep='\t',quote="", stringsAsFactors = F, header=F)
numNAs = apply(d,2,function(X){sum(is.na(X))})
if(ncol(d)==35){
d = d[,-10]
}
names(d) = c("spk",'state','round','date','t1','t2','t3','context','xx','meanings','inputLang','x1','t3','x2','x3','x4','t4','x5','x6','x7','x7b','contextSize','x8','x9','x10','x11','x12','x13', 'word','x15','target','x16','t5','x17')
if(d[1,]$contextSize!=6){
d[1,] = c(d[1,1:18],"-",d[1,19:33])
}
d$word = cleanWords(d$word)
startingLang = cleanWords(gsub(" ","",d[1,]$inputLang))
startingLang = gsub("\\[","",startingLang)
startingLang = gsub("\\]","",startingLang)
startingLang = strsplit(startingLang, ',')[[1]]
# identify innovations
d$innovation = !(d$word %in% startingLang  | duplicated(d$word))
wordCounts = table(d$word)
wordMeaningCounts = table(d$word,d$target)
res = data.frame(condition=rep(condition,sum(d$innovation)),chain=rep(chain,sum(d$innovation)),gen=rep(gen,sum(d$innovation)),round=rep(-1,sum(d$innovation)),parent=rep("",sum(d$innovation)),word=rep("",sum(d$innovation)),meaning=rep("",sum(d$innovation)),isSpikyMeaning=rep(F,sum(d$innovation)),increaseIconicity=rep(-1,sum(d$innovation)), wordCount=rep(-1,sum(d$innovation)) , wordCountSameMeaning=rep(-1,sum(d$innovation)), stringsAsFactors = F)
currentParents = startingLang
rcount = 1
for(i in 1:nrow(d)){
word = d[i,]$word
meaning = d[i,]$target
if(d[i,]$innovation){
parent = currentParents[meaning+1]
oldIconicity = getIconicity(parent)
newIconicity = getIconicity(word)
increaseIconicity = newIconicity - oldIconicity
isSpikyMeaning = meaning<=5
if(!isSpikyMeaning){
increaseIconicity = oldIconicity - newIconicity
}
wordsUsedInSameMeaning = wordMeaningCounts[word, meaning+1]
res[rcount,] = c(condition,chain,gen,i,parent,word,meaning,isSpikyMeaning,increaseIconicity,wordCounts[word], wordsUsedInSameMeaning)
rcount = rcount + 1
}
currentParents[meaning+1] = word
}
for(x in c("increaseIconicity",'wordCount','wordCountSameMeaning')){
res[,x] = as.numeric(res[,x])
}
return(res)
}
folders = list.dirs("../data/trials/", recursive=F)
folders = folders[grepl("MT_Exp",folders)]
datax = data.frame()
for(i in 1:length(folders)){
print(folders[i])
dx = processGeneration(folders[i])
datax = rbind(datax,dx)
}
hist(datax$increaseIconicity)
hist(datax[datax$condition=='Comm',]$increaseIconicity)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
dens.comm = density(datax[datax$condition=='Comm',]$increaseIconicity)
datax[datax$condition=='Comm',]$increaseIconicity
datax[is.na(datax$increaseIconicity),]
ratings.letters
getIconicity("size")
getIconicity("erdeya")
getIconicity("erdea")
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
getIconicity <- function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating, na.rm=T)
}
####
cleanWords = function(x){
gsub("รง",'c',x)
}
processGeneration = function(folder){
bits = strsplit(folder,"_")[[1]]
chain = bits[4]
gen = bits[5]
condition =   "Comm"
if(!"Comm" %in% bits){
condition = "Learn"
}
resFile = list.files(folder, pattern='*.OUT')
d = read.delim(paste(folder,"/", resFile,sep=''),sep='\t',quote="", stringsAsFactors = F, header=F)
numNAs = apply(d,2,function(X){sum(is.na(X))})
if(ncol(d)==35){
d = d[,-10]
}
names(d) = c("spk",'state','round','date','t1','t2','t3','context','xx','meanings','inputLang','x1','t3','x2','x3','x4','t4','x5','x6','x7','x7b','contextSize','x8','x9','x10','x11','x12','x13', 'word','x15','target','x16','t5','x17')
if(d[1,]$contextSize!=6){
d[1,] = c(d[1,1:18],"-",d[1,19:33])
}
d$word = cleanWords(d$word)
startingLang = cleanWords(gsub(" ","",d[1,]$inputLang))
startingLang = gsub("\\[","",startingLang)
startingLang = gsub("\\]","",startingLang)
startingLang = strsplit(startingLang, ',')[[1]]
# identify innovations
d$innovation = !(d$word %in% startingLang  | duplicated(d$word))
wordCounts = table(d$word)
wordMeaningCounts = table(d$word,d$target)
res = data.frame(condition=rep(condition,sum(d$innovation)),chain=rep(chain,sum(d$innovation)),gen=rep(gen,sum(d$innovation)),round=rep(-1,sum(d$innovation)),parent=rep("",sum(d$innovation)),word=rep("",sum(d$innovation)),meaning=rep("",sum(d$innovation)),isSpikyMeaning=rep(F,sum(d$innovation)),increaseIconicity=rep(-1,sum(d$innovation)), wordCount=rep(-1,sum(d$innovation)) , wordCountSameMeaning=rep(-1,sum(d$innovation)), stringsAsFactors = F)
currentParents = startingLang
rcount = 1
for(i in 1:nrow(d)){
word = d[i,]$word
meaning = d[i,]$target
if(d[i,]$innovation){
parent = currentParents[meaning+1]
oldIconicity = getIconicity(parent)
newIconicity = getIconicity(word)
increaseIconicity = newIconicity - oldIconicity
isSpikyMeaning = meaning<=5
if(!isSpikyMeaning){
increaseIconicity = oldIconicity - newIconicity
}
wordsUsedInSameMeaning = wordMeaningCounts[word, meaning+1]
res[rcount,] = c(condition,chain,gen,i,parent,word,meaning,isSpikyMeaning,increaseIconicity,wordCounts[word], wordsUsedInSameMeaning)
rcount = rcount + 1
}
currentParents[meaning+1] = word
}
for(x in c("increaseIconicity",'wordCount','wordCountSameMeaning')){
res[,x] = as.numeric(res[,x])
}
return(res)
}
folders = list.dirs("../data/trials/", recursive=F)
folders = folders[grepl("MT_Exp",folders)]
datax = data.frame()
for(i in 1:length(folders)){
print(folders[i])
dx = processGeneration(folders[i])
datax = rbind(datax,dx)
}
hist(datax$increaseIconicity)
hist(datax[datax$condition=='Comm',]$increaseIconicity)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
dens.comm = density(datax[datax$condition=='Comm',]$increaseIconicity)
dens.learn = density(datax[datax$condition=='Learn',]$increaseIconicity)
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
getIconicity <- function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating, na.rm=T)
}
####
cleanWords = function(x){
gsub("รง",'c',x)
}
processGeneration = function(folder){
bits = strsplit(folder,"_")[[1]]
chain = bits[4]
gen = bits[5]
condition =   "Comm"
if(!"Comm" %in% bits){
condition = "Learn"
}
resFile = list.files(folder, pattern='*.OUT')
d = read.delim(paste(folder,"/", resFile,sep=''),sep='\t',quote="", stringsAsFactors = F, header=F)
numNAs = apply(d,2,function(X){sum(is.na(X))})
if(ncol(d)==35){
d = d[,-10]
}
names(d) = c("spk",'state','round','date','t1','t2','t3','context','xx','meanings','inputLang','x1','t3','x2','x3','x4','t4','x5','x6','x7','x7b','contextSize','x8','x9','x10','x11','x12','x13', 'word','x15','target','x16','t5','x17')
if(d[1,]$contextSize!=6){
d[1,] = c(d[1,1:18],"-",d[1,19:33])
}
d$word = cleanWords(d$word)
startingLang = cleanWords(gsub(" ","",d[1,]$inputLang))
startingLang = gsub("\\[","",startingLang)
startingLang = gsub("\\]","",startingLang)
startingLang = strsplit(startingLang, ',')[[1]]
# identify innovations
d$innovation = !(d$word %in% startingLang  | duplicated(d$word))
wordCounts = table(d$word)
wordMeaningCounts = table(d$word,d$target)
res = data.frame(condition=rep(condition,sum(d$innovation)),chain=rep(chain,sum(d$innovation)),gen=rep(gen,sum(d$innovation)),round=rep(-1,sum(d$innovation)),parent=rep("",sum(d$innovation)),word=rep("",sum(d$innovation)),meaning=rep("",sum(d$innovation)),isSpikyMeaning=rep(F,sum(d$innovation)),increaseIconicity=rep(-1,sum(d$innovation)), wordCount=rep(-1,sum(d$innovation)) , wordCountSameMeaning=rep(-1,sum(d$innovation)), stringsAsFactors = F)
currentParents = startingLang
rcount = 1
for(i in 1:nrow(d)){
word = d[i,]$word
meaning = d[i,]$target
if(d[i,]$innovation){
parent = currentParents[meaning+1]
oldIconicity = getIconicity(parent)
newIconicity = getIconicity(word)
increaseIconicity = newIconicity - oldIconicity
isSpikyMeaning = meaning<=5
if(!isSpikyMeaning){
increaseIconicity = oldIconicity - newIconicity
}
wordsUsedInSameMeaning = wordMeaningCounts[word, meaning+1]
res[rcount,] = c(condition,chain,gen,i,parent,word,meaning,isSpikyMeaning,increaseIconicity,wordCounts[word], wordsUsedInSameMeaning)
rcount = rcount + 1
}
currentParents[meaning+1] = word
}
for(x in c("increaseIconicity",'wordCount','wordCountSameMeaning')){
res[,x] = as.numeric(res[,x])
}
return(res)
}
folders = list.dirs("../data/trials/", recursive=F)
folders = folders[grepl("MT_Exp",folders)]
datax = data.frame()
for(i in 1:length(folders)){
print(folders[i])
dx = processGeneration(folders[i])
datax = rbind(datax,dx)
}
hist(datax$increaseIconicity)
hist(datax[datax$condition=='Comm',]$increaseIconicity)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
dens.comm = density(datax[datax$condition=='Comm',]$increaseIconicity)
dens.learn = density(datax[datax$condition=='Learn',]$increaseIconicity)
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
getIconicity <- function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating, na.rm=T)
}
####
cleanWords = function(x){
gsub("รง",'c',x)
}
processGeneration = function(folder){
bits = strsplit(folder,"_")[[1]]
chain = bits[4]
gen = bits[5]
condition =   "Comm"
if(!"Comm" %in% bits){
condition = "Learn"
}
resFile = list.files(folder, pattern='*.OUT')
d = read.delim(paste(folder,"/", resFile,sep=''),sep='\t',quote="", stringsAsFactors = F, header=F)
numNAs = apply(d,2,function(X){sum(is.na(X))})
if(ncol(d)==35){
d = d[,-10]
}
names(d) = c("spk",'state','round','date','t1','t2','t3','context','xx','meanings','inputLang','x1','t3','x2','x3','x4','t4','x5','x6','x7','x7b','contextSize','x8','x9','x10','x11','x12','x13', 'word','x15','target','x16','t5','x17')
if(d[1,]$contextSize!=6){
d[1,] = c(d[1,1:18],"-",d[1,19:33])
}
d$word = cleanWords(d$word)
startingLang = cleanWords(gsub(" ","",d[1,]$inputLang))
startingLang = gsub("\\[","",startingLang)
startingLang = gsub("\\]","",startingLang)
startingLang = strsplit(startingLang, ',')[[1]]
# identify innovations
d$innovation = !(d$word %in% startingLang  | duplicated(d$word))
wordCounts = table(d$word)
wordMeaningCounts = table(d$word,d$target)
res = data.frame(condition=rep(condition,sum(d$innovation)),chain=rep(chain,sum(d$innovation)),gen=rep(gen,sum(d$innovation)),round=rep(-1,sum(d$innovation)),parent=rep("",sum(d$innovation)),word=rep("",sum(d$innovation)),meaning=rep("",sum(d$innovation)),isSpikyMeaning=rep(F,sum(d$innovation)),increaseIconicity=rep(-1,sum(d$innovation)), wordCount=rep(-1,sum(d$innovation)) , wordCountSameMeaning=rep(-1,sum(d$innovation)), stringsAsFactors = F)
currentParents = startingLang
rcount = 1
for(i in 1:nrow(d)){
word = d[i,]$word
meaning = d[i,]$target
if(d[i,]$innovation){
parent = currentParents[meaning+1]
oldIconicity = getIconicity(parent)
newIconicity = getIconicity(word)
increaseIconicity = newIconicity - oldIconicity
isSpikyMeaning = meaning<=5
if(!isSpikyMeaning){
increaseIconicity = oldIconicity - newIconicity
}
wordsUsedInSameMeaning = wordMeaningCounts[word, meaning+1]
res[rcount,] = c(condition,chain,gen,i,parent,word,meaning,isSpikyMeaning,increaseIconicity,wordCounts[word], wordsUsedInSameMeaning)
rcount = rcount + 1
}
currentParents[meaning+1] = word
}
for(x in c("increaseIconicity",'wordCount','wordCountSameMeaning')){
res[,x] = as.numeric(res[,x])
}
return(res)
}
folders = list.dirs("../data/trials/", recursive=F)
folders = folders[grepl("MT_Exp",folders)]
datax = data.frame()
for(i in 1:length(folders)){
print(folders[i])
dx = processGeneration(folders[i])
datax = rbind(datax,dx)
}
hist(datax$increaseIconicity)
hist(datax[datax$condition=='Comm',]$increaseIconicity)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
dens.comm = density(datax[datax$condition=='Comm',]$increaseIconicity)
dens.learn = density(datax[datax$condition=='Learn',]$increaseIconicity)
plot(dens.comm)
lines(dens.learn)
plot(dens.comm)
lines(dens.learn, col=2)
plot(dens.comm, main='', xlab='Change in iconicity')
lines(dens.learn, col=2)
lm(increaseIconicity ~ condition * isSpikyMeaning ,data=datax)
summary(lm(increaseIconicity ~ condition * isSpikyMeaning ,data=datax))
summary(lm(increaseIconicity ~ condition * isSpikyMeaning + wordCountSameMeaning,data=datax))
summary(lm(increaseIconicity ~ condition * isSpikyMeaning + wordCount,data=datax))
summary(lm(increaseIconicity ~ condition * isSpikyMeaning *wordCount,data=datax))
summary(lm(increaseIconicity ~ condition * isSpikyMeaning *wordCount,data=datax))
summary(lm(increaseIconicity ~ (condition * isSpikyMeaning) + (condition*wordCount),data=datax))
summary(lm(increaseIconicity ~  (condition*wordCount),data=datax))
summary(lm(increaseIconicity ~  (condition*wordCountSameMeaning),data=datax))
summary(lm(increaseIconicity ~  (condition*wordCount),data=datax))
library(gplots)
plotmeans(increaseIconicity ~ condition*isSpikyMeaning, data=datax)
plotmeans(increaseIconicity ~ condition:isSpikyMeaning, data=datax)
plotmeans(increaseIconicity ~ paste(condition,isSpikyMeaning), data=datax)
bits
!"Comm" %in% bits
table(datax$wordCount)
table(datax$wordCountSameMeaning)
summary(lm(increaseIconicity ~  (condition*I(wordCount>1),data=datax))
summary(lm(increaseIconicity ~  (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~  (condition*I(wordCountSameMeaning>1)),data=datax))
summary(lm(increaseIconicity ~  (condition*I(wordCount>1)),data=datax))
dim(datax)
summary(lm(increaseIconicity ~ round + (condition*I(wordCount>1)),data=datax))
library(gplots)
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
getIconicity <- function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating, na.rm=T)
}
####
cleanWords = function(x){
gsub("รง",'c',x)
}
processGeneration = function(folder){
bits = strsplit(folder,"_")[[1]]
chain = bits[4]
gen = bits[5]
condition =   "Comm"
if(!"Comm" %in% bits){
condition = "Learn"
}
resFile = list.files(folder, pattern='*.OUT')
d = read.delim(paste(folder,"/", resFile,sep=''),sep='\t',quote="", stringsAsFactors = F, header=F)
numNAs = apply(d,2,function(X){sum(is.na(X))})
if(ncol(d)==35){
d = d[,-10]
}
names(d) = c("spk",'state','round','date','t1','t2','t3','context','xx','meanings','inputLang','x1','t3','x2','x3','x4','t4','x5','x6','x7','x7b','contextSize','x8','x9','x10','x11','x12','x13', 'word','x15','target','x16','t5','x17')
if(d[1,]$contextSize!=6){
d[1,] = c(d[1,1:18],"-",d[1,19:33])
}
d$word = cleanWords(d$word)
startingLang = cleanWords(gsub(" ","",d[1,]$inputLang))
startingLang = gsub("\\[","",startingLang)
startingLang = gsub("\\]","",startingLang)
startingLang = strsplit(startingLang, ',')[[1]]
# identify innovations
d$innovation = !(d$word %in% startingLang  | duplicated(d$word))
wordCounts = table(d$word)
wordMeaningCounts = table(d$word,d$target)
res = data.frame(condition=rep(condition,sum(d$innovation)),chain=rep(chain,sum(d$innovation)),gen=rep(gen,sum(d$innovation)),round=rep(-1,sum(d$innovation)),parent=rep("",sum(d$innovation)),word=rep("",sum(d$innovation)),meaning=rep("",sum(d$innovation)),isSpikyMeaning=rep(F,sum(d$innovation)),increaseIconicity=rep(-1,sum(d$innovation)), wordCount=rep(-1,sum(d$innovation)) , wordCountSameMeaning=rep(-1,sum(d$innovation)), stringsAsFactors = F)
currentParents = startingLang
rcount = 1
for(i in 1:nrow(d)){
word = d[i,]$word
meaning = d[i,]$target
if(d[i,]$innovation){
parent = currentParents[meaning+1]
oldIconicity = getIconicity(parent)
newIconicity = getIconicity(word)
# If it's a spiky word, then we predict spikiness rating should go up
#  if so, new iconicity > old iconicity, so this gives positive number
increaseIconicity = newIconicity - oldIconicity
# but if it's not a spiky meaning, we predict the rating should go down
isSpikyMeaning = meaning<=5
if(!isSpikyMeaning){
increaseIconicity = oldIconicity - newIconicity
}
wordsUsedInSameMeaning = wordMeaningCounts[word, meaning+1]
res[rcount,] = c(condition,chain,gen,i,parent,word,meaning,isSpikyMeaning,increaseIconicity,wordCounts[word], wordsUsedInSameMeaning)
rcount = rcount + 1
}
currentParents[meaning+1] = word
}
for(x in c("increaseIconicity",'wordCount','wordCountSameMeaning','round')){
res[,x] = as.numeric(res[,x])
}
return(res)
}
folders = list.dirs("../data/trials/", recursive=F)
folders = folders[grepl("MT_Exp",folders)]
datax = data.frame()
for(i in 1:length(folders)){
print(folders[i])
dx = processGeneration(folders[i])
datax = rbind(datax,dx)
}
plotmeans(increaseIconicity ~ paste(condition,isSpikyMeaning), data=datax)
summary(lm(increaseIconicity ~ round + (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~ round * (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~ (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~ condition*isSpikyMeaning,data=datax))
aov(increaseIconicity ~ condition*isSpikyMeaning)
aov(increaseIconicity ~ as.factor(condition)*as.factor(isSpikyMeaning))
aov(increaseIconicity ~ as.factor(condition)*as.factor(isSpikyMeaning), data=datax)
summary(aov(increaseIconicity ~ as.factor(condition)*as.factor(isSpikyMeaning), data=datax))
head(datax)
library(gplots)
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")
##
# Check ratings for letters correlate with overall ratings
ratings = read.csv("../data/ratings/Sean_ratings.csv", stringsAsFactors = F)
ratings.letters = ratings[nchar(ratings$string)==1,]
rownames(ratings.letters) = ratings.letters$string
ratings.words = ratings[nchar(ratings$string)!=1,]
ratings.words$letterRating = sapply(ratings.words$string, function(X){
mean(ratings.letters[strsplit(X,'')[[1]],]$rating)
})
plot(ratings.words$rating,ratings.words$letterRating)
cor.test(ratings.words$rating,ratings.words$letterRating)
plot(dens.comm, main='', xlab='Change in iconicity')
lines(dens.learn, col=2)
abline(h=0)
abline(h=1)
abline(v=0)
hist(datax[datax$condition=='Learn',]$increaseIconicity)
summary(lm(increaseIconicity ~ condition*isSpikyMeaning,data=datax))
summary(lm(increaseIconicity ~ (condition*I(wordCount>1)),data=datax))
names(datax)
summary(lm(increaseIconicity ~ round + condition*isSpikyMeaning,data=datax))
summary(lm(increaseIconicity ~ round + (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~ gen + (condition*I(wordCount>1)),data=datax))
datax$gen = as.numeric(datax$gen)
summary(lm(increaseIconicity ~ gen + (condition*I(wordCount>1)),data=datax))
summary(lm(increaseIconicity ~ gen*condition + (condition*I(wordCount>1)),data=datax))
range(datax$round)
summary(lm(increaseIconicity ~ (condition*I(round>24)),data=datax))
summary(lm(increaseIconicity ~ (condition*I(datax$wordCountSameMeaning>1)),data=datax))
summary(lm(increaseIconicity ~ (condition*datax$wordCountSameMeaning>),data=datax))
summary(lm(increaseIconicity ~ (condition*datax$wordCountSameMeaning),data=datax))
summary(lm(increaseIconicity ~ (condition*datax$wordCount),data=datax[datax$gen>2,]))
summary(lm(increaseIconicity ~ (condition*wordCount),data=datax[datax$gen>2,]))
summary(lm(increaseIconicity ~ (condition*wordCountSameMeaning),data=datax[datax$gen>2,]))
summary(lm(increaseIconicity ~ (condition*wordCountSameMeaning),data=datax[datax$gen>3,]))
summary(lm(increaseIconicity ~ (condition*wordCountSameMeaning),data=datax[datax$gen>4,]))
write.csv(datax, file="../results/IncreaseInIconicity.csv")
