---
title: "The interactive origin of iconiciy: Mixed effects models"
output: 
  pdf_document:
    toc: true
---

\newpage

# Introduction

This file contains an analysis of the spikiness ratings of the final output languages and the accuracy of guessing during the experiments.  The spikiness ratings are not bimodally disributed, so the analysis of spikiness ratings is done using both the continuous spikiness rating values and a binarised version of the ratings.

# Spikiness ratings

## Load libraries

```{r message=FALSE, warning=FALSE}

library(gplots)
library(lattice)
library(ggplot2)
library(lme4)
library(party)
library(sjPlot)
```

```{r echo=F}
setwd("~/Documents/MPI/MonicaIconicity/SelectionAnalysis/analysis/")

getMEText = function(r,ef, wald=NULL){

AIC = r[2,]$AIC
loglikDiff = signif(diff(r$logLik),2)
chi = round(r$Chisq[2],2)
df = r$`Chi Df`[2]
p = signif(r$`Pr(>Chisq)`[2],2)

wald.text = ""

if(!is.null(wald)){
  est = signif(wald[1],2)
  stder = signif(wald[2],2)
  t = signif(wald[3],2)
  wptext = ""
  if(!is.na(wald[4])){
    wptext = paste(", Wald p =",signif(wald[4],2))
  }
  wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
}

begin = 'There was no significant'
if(p <0.1){
  begin = "There was a marginal"
}
if(p < 0.05){
  begin = 'There was a significant'  
}


return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
             loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
}

```

## Load data

```{r}
finalLangs = read.csv("../data/finalLanguages/FinalLanguages.csv", stringsAsFactors = F)
# convert labels to English
finalLangs$Shape[finalLangs$Shape=="Picudo"] = "Spiky"
finalLangs$Shape[finalLangs$Shape=="Redondo"] = "Round"

# load all trial data
alldatx = read.csv("../results/AllTrialData.csv",stringsAsFactors = F)
```

Center spikiness ratings and re-level factors.

```{r}
finalLangs$RatedSpikiness.center = 
  finalLangs$RatedSpikiness- mean(finalLangs$RatedSpikiness)

finalLangs$Cond = factor(finalLangs$Cond, levels=c("Learn","Communication"))
finalLangs$Shape = factor(finalLangs$Shape, levels=c("Round","Spiky"))

```

Plot the data by item (all conditions, all generations)

```{r}
par(mar=c(8,4,2,2))
plotmeans(finalLangs$RatedSpikiness.center~finalLangs$Item, las=2, xlab="", connect=F)
```

There are differences between items

## Mixed effects model

Build a series of models with random effects for Chain and Item.  


```{r}
# null model
m0 = lmer(RatedSpikiness.center ~ 1 + (1 |Chain)  + (1|Item), data=finalLangs)
# + condition
m1 = lmer(RatedSpikiness.center ~ Cond + (1 |Chain)  + (1|Item), data=finalLangs)
# + generation
m2 = lmer(RatedSpikiness.center ~ Cond + Gen + (1 |Chain) + (1|Item), data=finalLangs)
# + shape
m3 = lmer(RatedSpikiness.center ~ Cond + Gen + Shape + (1 |Chain)  
          + (1|Item), data=finalLangs)
# + interaction between shape and generation
m4 = lmer(RatedSpikiness.center ~ Cond + (Gen * Shape) + (1 |Chain)  
          + (1|Item), data=finalLangs)
# + interaction between condition and generation
m5 = lmer(RatedSpikiness.center ~ (Cond*Gen) + (Gen * Shape) + (1 |Chain)  
          + (1|Item), data=finalLangs)
# + interaction between shape and condition
m6 = lmer(RatedSpikiness.center ~ (Cond*Gen) + (Gen * Shape) + (Shape:Cond) 
          + (1 |Chain)  + (1|Item), data=finalLangs)
# + 3-way interaction
m7 = lmer(RatedSpikiness.center ~ Cond * Gen * Shape + (1 |Chain)  
          + (1|Item), data=finalLangs)
```

### Results

Look inside main model

```{r}
summary(m7)
```


Test the differences between model fits.

```{r}
anova(m0,m1,m2,m3,m4,m5,m6,m7)
```


`r getMEText(anova(m2,m3), "main effect of shape",summary(m7)$coef['ShapeSpiky',])`

`r getMEText(anova(m5,m6), "interaction between shape and condition", summary(m7)$coef['CondCommunication:ShapeSpiky',])`

`r getMEText(anova(m3,m4), "interaction between shape and generation", summary(m7)$coef['Gen:ShapeSpiky',])`

`r getMEText(anova(m6,m7), "three-way interaction between shape, condition and generation", summary(m7)$coef['CondCommunication:Gen:ShapeSpiky',])`


Plot the random effects.

```{r}
dotplot(ranef(m7, condVar=T))
```

Plot the fixed effects with error estiamtes from the final model.  The 3-way interaction between condition, generation and shape is marginaly significant:

```{r message=F, warning=F}
sjp.lmer(m7, type='fe', geom.colors=c(1,1))
```

\newpage

## Mixed effects model with binarised spikiness ratings

The spikiness ratings are not normally distributed:

```{r}
hist(finalLangs$RatedSpikiness)
```

So we binarise the variable into spiky/not spiky:

```{r}
finalLangs$RatedSpikiness.bin = finalLangs$RatedSpikiness >4
```

Run a series of models.  Note that intermediate models 5 and 6 do not converge, but the final model 7 does.

```{r}

mcontrol = glmerControl(optCtrl = list(maxfun = 500000))

mb0 = glmer(RatedSpikiness.bin ~ 1 + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb1 = glmer(RatedSpikiness.bin ~ Cond + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb2 = glmer(RatedSpikiness.bin ~ Cond + Gen + (1 |Chain) + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb3 = glmer(RatedSpikiness.bin ~ Cond + Gen + Shape + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb4 = glmer(RatedSpikiness.bin ~ Cond + (Gen * Shape) + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb5 = glmer(RatedSpikiness.bin ~ (Cond*Gen) + (Gen * Shape) + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb6 = glmer(RatedSpikiness.bin ~ (Cond*Gen) + (Gen * Shape) + (Shape:Cond) + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
mb7 = glmer(RatedSpikiness.bin ~ Cond * Gen * Shape + (1 |Chain)  + (1|Item), 
            data=finalLangs, family=binomial, control = mcontrol)
```

### Results

Look inside main model

```{r}
summary(mb7)
```

Test model comparison:

```{r}
anova(mb0,mb1,mb2,mb3,mb4,mb5,mb6,mb7)
```

`r getMEText(anova(mb2,mb3), "main effect of shape",summary(mb7)$coef['ShapeSpiky',])`

`r getMEText(anova(mb5,mb6), "interaction between shape and condition", summary(mb7)$coef['CondCommunication:ShapeSpiky',])`

`r getMEText(anova(mb3,mb4), "interaction between shape and generation", summary(mb7)$coef['Gen:ShapeSpiky',])`

`r getMEText(anova(mb6,mb7), "three-way interaction between shape, condition and generation", summary(mb7)$coef['CondCommunication:Gen:ShapeSpiky',])`


Plot random effects of final model

```{r}
dotplot(ranef(mb7,  condVar=T))
```

Plot fixed effects with standard error from final model.

```{r message=F, warning=F}
sjp.lmer(mb7, type='fe', geom.colors=c(1,1))
```

\newpage

## Binary tree analysis

We use a binary decision tree to predict spikiness ratings by condition, generation, item shape, item colour and item border type.

The results agree with those above, namely that the main effects are for shape, but spiky meanings are rated as more spiky in the communication condition

```{r}
finalLangs2 = finalLangs
finalLangs2$Shape = factor(finalLangs2$Shape)
finalLangs2$Colour = factor(finalLangs2$Colour)
finalLangs2$Border = factor(finalLangs2$Border)
finalLangs2$Cond = factor(finalLangs2$Cond)

cx = ctree(RatedSpikiness~Cond+Gen+Shape+Colour+Border, data=finalLangs2)
plot(cx)

```

\newpage

# Accuracy



## Load data

Note that the column *Human* in the data indicates whether the signal was sent by a human.  This is always the case in the communication condition, but only true for half of the trials in the learning condition.  In the learning condition, when *Human* is `FALSE`, the human participant is guessing meaning from the signal sent by the program. 

```{r}
datax = read.csv("../results/IncreaseInIconicity.csv", stringsAsFactors = F)
alldatx = read.csv("../results/AllTrialData.csv", stringsAsFactors = F)
```

The mean proportion of correct guesses in the communication condition was `r round((sum(alldatx[alldatx$condition=="Comm",]$correctGuess) / sum(alldatx$condition=="Comm"))*100,2)
`%.  The mean proportion of correct guesses by the human participant in the learning condition was `r round((sum(alldatx[alldatx$condition=="Learn" & !alldatx$Human,]$correctGuess) / sum(alldatx$condition=="Learn" & !alldatx$Human))*100,2)`%.

Plot the correct guesses by generation (means and 95% confidence intervals):

```{r warning=F}
plotmeans(correctGuess~gen,alldatx[alldatx$condition=='Learn' & !alldatx$Human,], n.label = F)
plotmeans(correctGuess~gen,alldatx[alldatx$condition=='Comm',],add=T,col=2,barcol=2, n.label = F)
```


## Mixed effects model

Binomial mixed effects model, with random effects for chain, target item.  Test whether there are differences between conditions.

```{r}

ctrl = glmerControl(optCtrl = list(maxfun=50000))
# we want to exclude trials where the computer is guessing meanings 
# from the participant's signals in the learning condition
m0 = glmer(correctGuess ~ 1 + (1|chain) + (1|target.meaning) , 
    data=alldatx[alldatx$condition=='Comm' | (!alldatx$Human),],
    family = binomial, control= ctrl)

m1 = glmer(correctGuess ~ 1 + (1|chain) + (1|target.meaning) + (1|gen), 
    data=alldatx[alldatx$condition=='Comm' | (!alldatx$Human),], 
    family = binomial, control= ctrl)
m2 = glmer(correctGuess ~ condition + (1|chain) + (1|target.meaning)+ (1|gen), 
    data=alldatx[alldatx$condition=='Comm' | (!alldatx$Human),], 
    family = binomial, control= ctrl)
anova(m0,m1,m2)
```

`r getMEText(anova(m1,m2),ef = "main effect of condition", summary(m2)$coef[2,])
`

`r getMEText(anova(m0,m1),ef = "difference between generations")`  There is a weak trend for the proportion of correct guesses to increase by generation, as shown by the estimates for the random effects for generation:

```{r message=F, warning=F}
x = sjp.lmer(m2, sort.est='sort.all', prnt.plot=F,
             axis.labels=c("Chain",'Item','Generation'),
             geom.colors=c(1,1))
x$plot.list[[3]] + 
  xlab("Generation") + 
  ylab("Random effect (fit of increase in correct guesses)")
```

\newpage

## Iconicity and accuracy for innovations

Innovations are either more or less iconic than the words they replace.  There is no difference in how accurate the guesses are in terms of choosing the right item (see below, left), but the innovation tends to be more iconic when the shape of a meaning is guessed correctly (spiky or round).  That is, the iconicity is helping participants guess the shape of a target meaning correctly.

Note that this analysis only makes sense for the communication condition. 

```{r}
par(mfrow=c(1,2))
ylimx = c(-0.045,0.045)
plotmeans(increaseIconicity ~ paste(condition, correctGuess), 
          data = datax[datax$Human & datax$condition=="Comm",], 
          ylim=ylimx, legends = c("Incorrect","Correct"),
          xlab='',
          ylab="Increase in iconicity")
title("Guessing Item")
abline(h=0)
plotmeans(increaseIconicity ~ paste(condition, correctSpikiness), 
          data = datax[datax$Human& datax$condition=="Comm",], 
          ylim=ylimx,legends = c("Incorrect","Correct"),
          xlab='',
          ylab="Increase in iconicity")
title("Guessing Shape")
abline(h=0)
```

\newpage

### Mixed effects model for accuracy and iconicity

A mixed effects model predicting the increase in iconicity by whether the reciever selected the correct target item, and by whether the reciever selected an item which matched the target in the shape dimension, with random effects for chain, generation and item.  Note that it would make more intuitive sense to predict accuracy by increase in iconicity, but this way we can compare the effects of item accuracy versus shape accuracy.

```{r}
m0 = lmer(increaseIconicity ~ 1 + (1|chain) + (1|gen) + (1|meaning), 
          data=datax[datax$condition=="Comm",])

m1 = lmer(increaseIconicity ~ correctGuess + (1|chain) + (1|gen)+ (1|meaning), 
          data=datax[datax$condition=="Comm",])

m2 = lmer(increaseIconicity ~ correctGuess + correctSpikiness + (1|chain) + (1|gen)+ (1|meaning), 
          data=datax[datax$condition=="Comm",])

anova(m0,m1,m2)

summary(m2)
```

`r getMEText(anova(m0,m1), "main effect of guessing the item correctly",summary(m2)$coef['correctGuessTRUE',])`

`r getMEText(anova(m1,m2), "main effect of guessing the shape correctly",summary(m2)$coef['correctSpikinessTRUE',])`


Plot the fixed effects:

```{r message=F, warning=F}
sjp.glmer(m2, type='fe', geom.colors=c(1,1) )
```

Note that the model is probably overfitted, since the random effects are singulative. But the effect is clear from the plot of the raw data.

## Iconicity and accuracy for whole data

Make a variable that indicates the iconicity of a word according to its shape.  i.e. high if it aligns with shape, low if it does not.  In other words, reverse the scale for round meanings.

```{r}
alldatx$estimatedIconicity = alldatx$estimatedSpikinessRating

alldatx$estimatedIconicity[alldatx$target.meaning>5] = 
  7 - alldatx$estimatedIconicity[alldatx$target.meaning>5]

```

Plot the raw data

```{r}
par(mfrow=c(1,2))
ylimx= c(3.4,3.65)
plotmeans(estimatedIconicity~correctSpikiness, 
          data=alldatx[alldatx$condition=='Comm',],
          ylim = ylimx,
          xlab="Guessing shape",
          ylab="Iconicity",
          legends = c("Incorrect","Correct"),
          main="Communication")

plotmeans(estimatedIconicity~correctSpikiness, 
          data=alldatx[alldatx$condition=='Learn' &
                         (!alldatx$Human),],
          ylim = ylimx,
          xlab="Guessing shape",
          ylab="Iconicity",
          legends = c("Incorrect","Correct"),
          main="Learning")


```




\newpage

# Iconicity and systematicity

We would like to test whether there is a link between the increase in iconicity and the increase in systematicity for innovations.

Overall correlation between systematicity increase and iconicity increase:

```{r}
cor.test(datax[datax$Human,]$increaseIconicity,datax[datax$Human,]$systematicity.increase)
```

For the communication condition:

```{r}
cor.test(
  datax[datax$condition=="Comm",]$increaseIconicity,
  datax[datax$condition=="Comm",]$systematicity.increase)
```

For the learning condition:

```{r}
cor.test(
  datax[datax$condition=="Learn" & datax$Human,]$increaseIconicity,
  datax[datax$condition=="Learn" & datax$Human,]$systematicity.increase)
```

Simple linear model:

```{r}
summary(lm(increaseIconicity~systematicity.increase*condition, data=datax[datax$Human,]))
```

Significant main effect for systematicity increase and interaction.

## Mixed effects model

Build a series of mixed effects models predicting the increase in iconicity with random effects for chain and item.

```{r}

# select data - either trails from the communication condition
#  or from the learning condition when the human was the speaker
datax.sel = datax[datax$Human,]

# Null model, predicting increase in iconicity by condition and generation
m0 = lmer(increaseIconicity~condition*gen + (1|chain) + (1|meaning),
          data = datax.sel)

# Add main effect of systematicity increase
m1 = lmer(increaseIconicity~systematicity.increase+(condition*gen) + (1|chain) + (1|meaning), 
          data = datax.sel)

# Add interaction between Sys. and condition
m2 = lmer(increaseIconicity~systematicity.increase + (systematicity.increase:condition) +
            (condition*gen) + (1|chain) + (1|meaning), 
          data = datax.sel)

# Add 3-way interaction
m3 = lmer(increaseIconicity~systematicity.increase*condition*gen +
            (1|chain) + (1|meaning), 
          data = datax.sel)
```

## Results

Test the model fit.  Note that the model converges on signualtive random effect estimates.

```{r}
anova(m0,m1,m2,m3)
```

`r getMEText(anova(m1,m2),"interaction between systematicity increase and condition")`

Plot the fixed effects of model 2.  The relationship between systematicity and iconicity is more negative in the learning condition:

```{r}
sjp.lmer(m2,type='fe')
```

Plot differences in raw data:

```{r}
ylimx= c(-0.015,0.018)
par(mfrow=c(1,2))
plotmeans(systematicity.increase ~ increaseIconicity>0,
          data=datax[datax$condition=="Comm",], 
          legends = c("Decrease","Increase"), 
          xlab="Change in iconicity", 
          ylab="Change in systematicity",
          main = "Communication",
          ylim = ylimx)
abline(h=0)
plotmeans(systematicity.increase ~ increaseIconicity>0,
          data=datax[datax$Human & datax$condition=="Learn",], 
          legends = c("Decrease","Increase"), 
          xlab="Change in iconicity", 
          ylab="Change in systematicity",
          main = "Learning",
          ylim = ylimx)

abline(h=0)
```
